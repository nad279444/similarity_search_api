tasks:
  - name: Setup Ollama
    init: |
      # Create a local bin folder for Ollama
      mkdir -p $HOME/bin
      curl -L https://ollama.com/download/ollama-linux-amd64 -o $HOME/bin/ollama
      chmod +x $HOME/bin/ollama

      # Persist models in the workspace
      mkdir -p /workspace/.ollama

      # Add Ollama to PATH for all future shells
      echo 'export PATH=$HOME/bin:$PATH' >> ~/.bashrc
      echo 'export OLLAMA_MODELS=/workspace/.ollama' >> ~/.bashrc

    command: |
      # Set environment variables
      export PATH=$HOME/bin:$PATH
      export OLLAMA_MODELS=/workspace/.ollama
      
      # Start Ollama service in background
      ollama serve > /tmp/ollama.log 2>&1 &
      
      # Wait for Ollama to be ready
      echo "Waiting for Ollama to start..."
      sleep 5
      
      # Check if Ollama is running and pull model
      if pgrep -f "ollama serve" > /dev/null; then
        echo "Ollama is running, pulling llama3 model..."
        ollama pull llama3
        echo "Ollama setup complete!"
      else
        echo "Failed to start Ollama service"
      fi
      
      # Keep the terminal open
      bash

ports:
  - port: 11434
    onOpen: ignore
    visibility: public
