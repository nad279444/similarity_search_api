{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wikipedia in /home/gitpod/.pyenv/versions/3.12.11/lib/python3.12/site-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/gitpod/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/gitpod/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gitpod/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/gitpod/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /home/gitpod/.pyenv/versions/3.12.11/lib/python3.12/site-packages (from beautifulsoup4->wikipedia) (4.15.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from langchain_community.vectorstores import UpstashVectorStore\n",
        "from langchain_core.documents import Document\n",
        "import ollama\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import traceback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "URL configured: True\n",
            "Token configured: True\n",
            "URL: https://refined-dog-19948-us1-vector.upstash.io...\n"
          ]
        }
      ],
      "source": [
        "load_dotenv()\n",
        "\n",
        "UPSTASH_VECTOR_REST_URL = os.getenv(\"UPSTASH_VECTOR_REST_URL\")\n",
        "UPSTASH_VECTOR_REST_TOKEN = os.getenv(\"UPSTASH_VECTOR_REST_TOKEN\")\n",
        "\n",
        "print(f\"URL configured: {UPSTASH_VECTOR_REST_URL is not None}\")\n",
        "print(f\"Token configured: {UPSTASH_VECTOR_REST_TOKEN is not None}\")\n",
        "if UPSTASH_VECTOR_REST_URL:\n",
        "    print(f\"URL: {UPSTASH_VECTOR_REST_URL[:50]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Status Code: 200\n",
            "Response Headers: {'Date': 'Fri, 05 Sep 2025 13:40:39 GMT', 'Content-Type': 'application/json', 'Content-Length': '411', 'Connection': 'keep-alive', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains'}\n",
            "Raw Response: {\n",
            "  \"result\" : {\n",
            "    \"vectorCount\" : 0,\n",
            "    \"pendingVectorCount\" : 0,\n",
            "    \"indexSize\" : 0,\n",
            "    \"dimension\" : 768,\n",
            "    \"similarityFunction\" : \"COSINE\",\n",
            "    \"namespaces\" : {\n",
            "      \"\" : {\n",
            "        \"vectorCount\" : 0,\n",
            "        \"pendingVectorCount\" : 0\n",
            "      }\n",
            "    },\n",
            "    \"indexType\" : \"DENSE\",\n",
            "    \"denseIndex\" : {\n",
            "      \"dimension\" : 768,\n",
            "      \"similarityFunction\" : \"COSINE\",\n",
            "      \"embeddingModel\" : \"\"\n",
            "    }\n",
            "  }\n",
            "}...\n",
            "‚úÖ Upstash connection successful!\n",
            "Index info: {'result': {'vectorCount': 0, 'pendingVectorCount': 0, 'indexSize': 0, 'dimension': 768, 'similarityFunction': 'COSINE', 'namespaces': {'': {'vectorCount': 0, 'pendingVectorCount': 0}}, 'indexType': 'DENSE', 'denseIndex': {'dimension': 768, 'similarityFunction': 'COSINE', 'embeddingModel': ''}}}\n"
          ]
        }
      ],
      "source": [
        "# Test Upstash connection first\n",
        "def test_upstash_connection():\n",
        "    \"\"\"Test if Upstash API is accessible and returns valid JSON\"\"\"\n",
        "    try:\n",
        "        headers = {\n",
        "            'Authorization': f'Bearer {UPSTASH_VECTOR_REST_TOKEN}',\n",
        "            'Content-Type': 'application/json'\n",
        "        }\n",
        "        \n",
        "        # Test with info endpoint\n",
        "        response = requests.get(f\"{UPSTASH_VECTOR_REST_URL}/info\", headers=headers, timeout=10)\n",
        "        \n",
        "        print(f\"Status Code: {response.status_code}\")\n",
        "        print(f\"Response Headers: {dict(response.headers)}\")\n",
        "        print(f\"Raw Response: {response.text[:500]}...\")\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            try:\n",
        "                data = response.json()\n",
        "                print(f\"‚úÖ Upstash connection successful!\")\n",
        "                print(f\"Index info: {data}\")\n",
        "                return True, data\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"‚ùå JSONDecodeError: {e}\")\n",
        "                print(f\"Response is not valid JSON: {response.text}\")\n",
        "                return False, None\n",
        "        else:\n",
        "            print(f\"‚ùå HTTP Error {response.status_code}: {response.text}\")\n",
        "            return False, None\n",
        "            \n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ùå Request failed: {e}\")\n",
        "        return False, None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Unexpected error: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return False, None\n",
        "\n",
        "# Test the connection\n",
        "connection_ok, index_info = test_upstash_connection()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Upstash connection verified, proceeding...\n"
          ]
        }
      ],
      "source": [
        "# Only proceed if connection is working\n",
        "if not connection_ok:\n",
        "    print(\"\\nüö® UPSTASH CONNECTION FAILED!\")\n",
        "    print(\"\\nPossible solutions:\")\n",
        "    print(\"1. Check your UPSTASH_VECTOR_REST_URL and UPSTASH_VECTOR_REST_TOKEN in .env\")\n",
        "    print(\"2. Ensure your Upstash Vector index exists and is active\")\n",
        "    print(\"3. Create a new index at https://console.upstash.com with:\")\n",
        "    print(\"   - Dimension: 768 (for nomic-embed-text)\")\n",
        "    print(\"   - Embedding model enabled\")\n",
        "    print(\"4. Check if your index region is accessible\")\n",
        "    raise Exception(\"Cannot proceed without valid Upstash connection\")\n",
        "else:\n",
        "    print(\"‚úÖ Upstash connection verified, proceeding...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Embeddings working!\n",
            "Embedding dimension: 768\n",
            "Sample values: [0.03040738, 0.056143694, -0.1795196, -0.080891974, 0.04595056]\n"
          ]
        }
      ],
      "source": [
        "# Initialize embeddings\n",
        "try:\n",
        "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
        "    \n",
        "    # Test embedding generation\n",
        "    test_text = \"This is a test embedding\"\n",
        "    test_embedding = embeddings.embed_query(test_text)\n",
        "    \n",
        "    print(f\"‚úÖ Embeddings working!\")\n",
        "    print(f\"Embedding dimension: {len(test_embedding)}\")\n",
        "    print(f\"Sample values: {test_embedding[:5]}\")\n",
        "    \n",
        "    # Check if dimensions match index\n",
        "    if index_info and 'dimension' in index_info:\n",
        "        index_dim = index_info['dimension']\n",
        "        if len(test_embedding) != index_dim:\n",
        "            print(f\"‚ö†Ô∏è  DIMENSION MISMATCH!\")\n",
        "            print(f\"Embedding dimension: {len(test_embedding)}\")\n",
        "            print(f\"Index dimension: {index_dim}\")\n",
        "            print(f\"You need to create a new index with dimension {len(test_embedding)}\")\n",
        "        else:\n",
        "            print(f\"‚úÖ Dimensions match: {len(test_embedding)}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Embedding error: {e}\")\n",
        "    traceback.print_exc()\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ UpstashVectorStore initialized successfully\n"
          ]
        }
      ],
      "source": [
        "# Initialize Upstash Vector Store with error handling\n",
        "try:\n",
        "    store = UpstashVectorStore(\n",
        "        embedding=embeddings,\n",
        "        index_url=UPSTASH_VECTOR_REST_URL,\n",
        "        index_token=UPSTASH_VECTOR_REST_TOKEN,\n",
        "    )\n",
        "    print(\"‚úÖ UpstashVectorStore initialized successfully\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to initialize UpstashVectorStore: {e}\")\n",
        "    traceback.print_exc()\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing with a single document...\n",
            "‚úÖ Test document added successfully! Result: ['30d620e8-fc57-4318-9cec-c85be51baf36']\n",
            "‚úÖ Search successful! Found 0 results\n"
          ]
        }
      ],
      "source": [
        "# Test with a single document first\n",
        "try:\n",
        "    print(\"Testing with a single document...\")\n",
        "    test_doc = Document(\n",
        "        page_content=\"This is a test document to verify the Upstash integration works correctly.\",\n",
        "        metadata={\"source\": \"test\", \"title\": \"Test Document\"}\n",
        "    )\n",
        "    \n",
        "    # Try to add the test document\n",
        "    result = store.add_documents([test_doc])\n",
        "    print(f\"‚úÖ Test document added successfully! Result: {result}\")\n",
        "    \n",
        "    # Try to search\n",
        "    search_results = store.similarity_search(\"test document\", k=1)\n",
        "    print(f\"‚úÖ Search successful! Found {len(search_results)} results\")\n",
        "    \n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"‚ùå JSONDecodeError during test: {e}\")\n",
        "    print(\"This usually means:\")\n",
        "    print(\"1. Your index dimension doesn't match embedding dimension (768)\")\n",
        "    print(\"2. Your index wasn't created with embedding model support\")\n",
        "    print(\"3. API endpoint is returning HTML error page instead of JSON\")\n",
        "    print(\"\\nSolution: Create a new Upstash Vector index with:\")\n",
        "    print(\"- Dimension: 768\")\n",
        "    print(\"- Embedding model enabled\")\n",
        "    raise\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Test failed: {e}\")\n",
        "    traceback.print_exc()\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üöÄ Test passed! Proceeding with Wikipedia documents...\n",
            "Fetching: New York City, New York\n",
            "‚úÖ Loaded: New York City, New York (93891 chars)\n",
            "Fetching: Boise, Idaho\n",
            "‚úÖ Loaded: Boise, Idaho (51096 chars)\n",
            "\n",
            "Total documents loaded: 2\n"
          ]
        }
      ],
      "source": [
        "# If test passed, proceed with Wikipedia documents\n",
        "print(\"\\nüöÄ Test passed! Proceeding with Wikipedia documents...\")\n",
        "\n",
        "# Fetch Wikipedia pages\n",
        "documents = []\n",
        "cities = [\"New York City, New York\", \"Boise, Idaho\"]\n",
        "\n",
        "for city in cities:\n",
        "    try:\n",
        "        print(f\"Fetching: {city}\")\n",
        "        wikipedia_page_result = wikipedia.page(title=city)\n",
        "        doc = Document(\n",
        "            page_content=wikipedia_page_result.content,\n",
        "            metadata={\n",
        "                \"source\": f\"{wikipedia_page_result.url}\",\n",
        "                \"title\": city,\n",
        "            }\n",
        "        )\n",
        "        documents.append(doc)\n",
        "        print(f\"‚úÖ Loaded: {city} ({len(wikipedia_page_result.content)} chars)\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading {city}: {e}\")\n",
        "\n",
        "print(f\"\\nTotal documents loaded: {len(documents)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split into 244 chunks\n",
            "\n",
            "Sample chunk:\n",
            "Content: New York, often called New York City (NYC), is the most populous city in the United States. It is located at the southern tip of New York State on one of the world's largest natural harbors. The city ...\n",
            "Metadata: {'source': 'https://en.wikipedia.org/wiki/New_York_City', 'title': 'New York City, New York'}\n"
          ]
        }
      ],
      "source": [
        "# Split documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "\n",
        "docs = text_splitter.split_documents(documents)\n",
        "print(f\"Split into {len(docs)} chunks\")\n",
        "\n",
        "# Show sample chunk\n",
        "if docs:\n",
        "    print(f\"\\nSample chunk:\")\n",
        "    print(f\"Content: {docs[0].page_content[:200]}...\")\n",
        "    print(f\"Metadata: {docs[0].metadata}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing batch 1/49 (5 documents)\n",
            "‚úÖ Batch 1 inserted successfully. Total: 5/244\n",
            "\n",
            "Processing batch 2/49 (5 documents)\n",
            "‚úÖ Batch 2 inserted successfully. Total: 10/244\n",
            "\n",
            "Processing batch 3/49 (5 documents)\n",
            "‚úÖ Batch 3 inserted successfully. Total: 15/244\n",
            "\n",
            "Processing batch 4/49 (5 documents)\n",
            "‚úÖ Batch 4 inserted successfully. Total: 20/244\n",
            "\n",
            "Processing batch 5/49 (5 documents)\n",
            "‚úÖ Batch 5 inserted successfully. Total: 25/244\n",
            "\n",
            "Processing batch 6/49 (5 documents)\n",
            "‚úÖ Batch 6 inserted successfully. Total: 30/244\n",
            "\n",
            "Processing batch 7/49 (5 documents)\n",
            "‚úÖ Batch 7 inserted successfully. Total: 35/244\n",
            "\n",
            "Processing batch 8/49 (5 documents)\n",
            "‚úÖ Batch 8 inserted successfully. Total: 40/244\n",
            "\n",
            "Processing batch 9/49 (5 documents)\n",
            "‚úÖ Batch 9 inserted successfully. Total: 45/244\n",
            "\n",
            "Processing batch 10/49 (5 documents)\n",
            "‚úÖ Batch 10 inserted successfully. Total: 50/244\n",
            "\n",
            "Processing batch 11/49 (5 documents)\n",
            "‚úÖ Batch 11 inserted successfully. Total: 55/244\n",
            "\n",
            "Processing batch 12/49 (5 documents)\n",
            "‚úÖ Batch 12 inserted successfully. Total: 60/244\n",
            "\n",
            "Processing batch 13/49 (5 documents)\n",
            "‚úÖ Batch 13 inserted successfully. Total: 65/244\n",
            "\n",
            "Processing batch 14/49 (5 documents)\n",
            "‚úÖ Batch 14 inserted successfully. Total: 70/244\n",
            "\n",
            "Processing batch 15/49 (5 documents)\n",
            "‚úÖ Batch 15 inserted successfully. Total: 75/244\n",
            "\n",
            "Processing batch 16/49 (5 documents)\n",
            "‚úÖ Batch 16 inserted successfully. Total: 80/244\n",
            "\n",
            "Processing batch 17/49 (5 documents)\n",
            "‚úÖ Batch 17 inserted successfully. Total: 85/244\n",
            "\n",
            "Processing batch 18/49 (5 documents)\n",
            "‚úÖ Batch 18 inserted successfully. Total: 90/244\n",
            "\n",
            "Processing batch 19/49 (5 documents)\n",
            "‚úÖ Batch 19 inserted successfully. Total: 95/244\n",
            "\n",
            "Processing batch 20/49 (5 documents)\n",
            "‚úÖ Batch 20 inserted successfully. Total: 100/244\n",
            "\n",
            "Processing batch 21/49 (5 documents)\n",
            "‚úÖ Batch 21 inserted successfully. Total: 105/244\n",
            "\n",
            "Processing batch 22/49 (5 documents)\n",
            "‚úÖ Batch 22 inserted successfully. Total: 110/244\n",
            "\n",
            "Processing batch 23/49 (5 documents)\n",
            "‚úÖ Batch 23 inserted successfully. Total: 115/244\n",
            "\n",
            "Processing batch 24/49 (5 documents)\n",
            "‚úÖ Batch 24 inserted successfully. Total: 120/244\n",
            "\n",
            "Processing batch 25/49 (5 documents)\n",
            "‚úÖ Batch 25 inserted successfully. Total: 125/244\n",
            "\n",
            "Processing batch 26/49 (5 documents)\n",
            "‚úÖ Batch 26 inserted successfully. Total: 130/244\n",
            "\n",
            "Processing batch 27/49 (5 documents)\n",
            "‚úÖ Batch 27 inserted successfully. Total: 135/244\n",
            "\n",
            "Processing batch 28/49 (5 documents)\n",
            "‚úÖ Batch 28 inserted successfully. Total: 140/244\n",
            "\n",
            "Processing batch 29/49 (5 documents)\n",
            "‚úÖ Batch 29 inserted successfully. Total: 145/244\n",
            "\n",
            "Processing batch 30/49 (5 documents)\n",
            "‚úÖ Batch 30 inserted successfully. Total: 150/244\n",
            "\n",
            "Processing batch 31/49 (5 documents)\n",
            "‚úÖ Batch 31 inserted successfully. Total: 155/244\n",
            "\n",
            "Processing batch 32/49 (5 documents)\n",
            "‚úÖ Batch 32 inserted successfully. Total: 160/244\n",
            "\n",
            "Processing batch 33/49 (5 documents)\n",
            "‚úÖ Batch 33 inserted successfully. Total: 165/244\n",
            "\n",
            "Processing batch 34/49 (5 documents)\n",
            "‚úÖ Batch 34 inserted successfully. Total: 170/244\n",
            "\n",
            "Processing batch 35/49 (5 documents)\n",
            "‚úÖ Batch 35 inserted successfully. Total: 175/244\n",
            "\n",
            "Processing batch 36/49 (5 documents)\n",
            "‚úÖ Batch 36 inserted successfully. Total: 180/244\n",
            "\n",
            "Processing batch 37/49 (5 documents)\n",
            "‚úÖ Batch 37 inserted successfully. Total: 185/244\n",
            "\n",
            "Processing batch 38/49 (5 documents)\n",
            "‚úÖ Batch 38 inserted successfully. Total: 190/244\n",
            "\n",
            "Processing batch 39/49 (5 documents)\n",
            "‚úÖ Batch 39 inserted successfully. Total: 195/244\n",
            "\n",
            "Processing batch 40/49 (5 documents)\n",
            "‚úÖ Batch 40 inserted successfully. Total: 200/244\n",
            "\n",
            "Processing batch 41/49 (5 documents)\n",
            "‚úÖ Batch 41 inserted successfully. Total: 205/244\n",
            "\n",
            "Processing batch 42/49 (5 documents)\n",
            "‚úÖ Batch 42 inserted successfully. Total: 210/244\n",
            "\n",
            "Processing batch 43/49 (5 documents)\n",
            "‚úÖ Batch 43 inserted successfully. Total: 215/244\n",
            "\n",
            "Processing batch 44/49 (5 documents)\n",
            "‚úÖ Batch 44 inserted successfully. Total: 220/244\n",
            "\n",
            "Processing batch 45/49 (5 documents)\n",
            "‚úÖ Batch 45 inserted successfully. Total: 225/244\n",
            "\n",
            "Processing batch 46/49 (5 documents)\n",
            "‚úÖ Batch 46 inserted successfully. Total: 230/244\n",
            "\n",
            "Processing batch 47/49 (5 documents)\n",
            "‚úÖ Batch 47 inserted successfully. Total: 235/244\n",
            "\n",
            "Processing batch 48/49 (5 documents)\n",
            "‚úÖ Batch 48 inserted successfully. Total: 240/244\n",
            "\n",
            "Processing batch 49/49 (4 documents)\n",
            "‚úÖ Batch 49 inserted successfully. Total: 244/244\n",
            "\n",
            "üéâ All 244 documents indexed in Upstash successfully!\n"
          ]
        }
      ],
      "source": [
        "# Add documents in small batches with comprehensive error handling\n",
        "batch_size = 5  # Small batches to avoid timeouts\n",
        "total_inserted = 0\n",
        "failed_batches = []\n",
        "\n",
        "try:\n",
        "    for i in range(0, len(docs), batch_size):\n",
        "        batch = docs[i:i+batch_size]\n",
        "        batch_num = i//batch_size + 1\n",
        "        total_batches = (len(docs)-1)//batch_size + 1\n",
        "        \n",
        "        print(f\"\\nProcessing batch {batch_num}/{total_batches} ({len(batch)} documents)\")\n",
        "        \n",
        "        try:\n",
        "            # Add batch with timeout handling\n",
        "            inserted_vectors = store.add_documents(batch)\n",
        "            total_inserted += len(batch)\n",
        "            print(f\"‚úÖ Batch {batch_num} inserted successfully. Total: {total_inserted}/{len(docs)}\")\n",
        "            \n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"‚ùå JSONDecodeError in batch {batch_num}: {e}\")\n",
        "            failed_batches.append(batch_num)\n",
        "            print(\"This indicates a dimension mismatch or index configuration issue.\")\n",
        "            break  # Stop processing if we get JSON errors\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error in batch {batch_num}: {e}\")\n",
        "            failed_batches.append(batch_num)\n",
        "            # Continue with next batch\n",
        "            continue\n",
        "    \n",
        "    if failed_batches:\n",
        "        print(f\"\\n‚ö†Ô∏è  Some batches failed: {failed_batches}\")\n",
        "        print(f\"Successfully inserted: {total_inserted}/{len(docs)} documents\")\n",
        "    else:\n",
        "        print(f\"\\nüéâ All {total_inserted} documents indexed in Upstash successfully!\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Critical error during batch processing: {e}\")\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Testing similarity search...\n",
            "Query: What is the population of New York?\n",
            "Found 3 results:\n",
            "\n",
            "Result 1:\n",
            "Source: https://en.wikipedia.org/wiki/New_York_City\n",
            "Title: New York City, New York\n",
            "Content: Based on data from the 2020 census, New York City comprised about 43.6% of the state's population of 20,202,320, and about 39% of the population of the New York metropolitan area. The majority of New ...\n",
            "\n",
            "Result 2:\n",
            "Source: https://en.wikipedia.org/wiki/New_York_City\n",
            "Title: New York City, New York\n",
            "Content: New York City is the most populous city in the United States, with 8,804,190 residents as of the 2020 census, its highest decennial count ever, incorporating more immigration into the city than outmig...\n",
            "\n",
            "Result 3:\n",
            "Source: https://en.wikipedia.org/wiki/New_York_City\n",
            "Title: New York City, New York\n",
            "Content: Between 2010 and 2020, New York City‚Äôs population grew by 629,000 residents, more than the total growth of the next four largest American cities (Los Angeles, Chicago, Houston, and Phoenix) combined. ...\n"
          ]
        }
      ],
      "source": [
        "# Test similarity search if any documents were inserted\n",
        "if total_inserted > 0:\n",
        "    try:\n",
        "        print(\"\\nüîç Testing similarity search...\")\n",
        "        query = \"What is the population of New York?\"\n",
        "        results = store.similarity_search(query, k=3)\n",
        "        \n",
        "        print(f\"Query: {query}\")\n",
        "        print(f\"Found {len(results)} results:\")\n",
        "        \n",
        "        for i, result in enumerate(results):\n",
        "            print(f\"\\nResult {i+1}:\")\n",
        "            print(f\"Source: {result.metadata.get('source', 'Unknown')}\")\n",
        "            print(f\"Title: {result.metadata.get('title', 'Unknown')}\")\n",
        "            print(f\"Content: {result.page_content[:200]}...\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Search failed: {e}\")\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"\\n‚ùå No documents were successfully inserted, skipping search test.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Boise,_Idaho', 'title': 'Boise, Idaho'}, page_content='=== Etymology ===\\n\\nThe origin of the name is uncertain. One account credits Capt. B. L. E. Bonneville of the U.S. Army as its source. After trekking for weeks through dry and rough terrain, his exploration party reached an overlook with a view of the Boise River Valley. The place where they stood is called Bonneville Point, located on the Oregon Trail east of the city. According to the story, a French-speaking guide, overwhelmed by the sight of the verdant river, yelled \"Les bois! Les bois!\" (\"The woods! The woods!\")‚Äîand the name stuck.\\nThe name may also derive from earlier mountain men who named the river that flows through the city. In the 1820s, French Canadian fur trappers associated with the British-owned Hudson\\'s Bay Company set trap lines in the vicinity. Set in a high-desert area, the tree-lined valley of the Boise River became a distinct landmark, an oasis dominated by cottonwood trees. This led the French trappers to call the area \"la rivi√®re bois√©e\" (\"the wooded river\").'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Boise,_Idaho', 'title': 'Boise, Idaho'}, page_content='Boise began to earn its City of Trees nickname in this period with a popular focus on a range of tree planting projects. Thomas J. Davis planted several thousand fruit trees in 1864 and several other early businessmen either founded nurseries or orchards of their own. In the 1870s tree planting began in earnest in downtown Boise led by prominent hotels as well as businessmen and residents. In 1907 Davis donated 43 acres of his orchard property to the city for use as a park in the name of his wife Julia. Commercial agriculture continued to expand, but was slowed by the lack of reliable rail links to regional and national markets and by a lack of large scale irrigation projects, which themselves were often tied to hoped-for railroad projects for financing. A.D. Foote, a successful mining engineer, drew up plans to irrigate up to 500,000 acres immediately south of Boise in 1882, but progress was halting and smaller farms were the norm until after the turn of the century with most located'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/New_York_City', 'title': 'New York City, New York'}, page_content=\"== Etymology ==\\n\\nIn 1664, New York was named in honor of the Duke of York (later King James II of England). James's elder brother, King Charles II, appointed him proprietor of the former territory of New Netherland, including the city of New Amsterdam, when the Kingdom of England seized it from Dutch control. New Netherland was renamed the Province of New York (now New York State).\\n\\n\\n== History ==\\n\\n\\n=== Early history ===\")]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever = store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "retriever.invoke(\"what is the  named after  trees?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = ChatOllama(model=\"llama3\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "parser = StrOutputParser()\n",
        "\n",
        "chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm | parser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "According to the provided context, bagels are best known in New York City.\n"
          ]
        }
      ],
      "source": [
        "response = chain.invoke(\"What type of food is best known in New York City?\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "3.12.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
